{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database to File-based Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as ipw\n",
    "from IPython.display import display, HTML\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Database\n",
    "\n",
    "- Username and password are provided on the MBSI Slack channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host=\"35.233.174.193\",port=3306,\n",
    "                           user=input(\"Enter username for MIMIC2 database\"),\n",
    "                           passwd=getpass.getpass(\"Enter password for MIMIC2 database\"),\n",
    "                           db='mimic2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much data is in this database?\n",
    "\n",
    "- How many unique patients?\n",
    "- How many hospitalizations?\n",
    "- How many notes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.read_sql_query('SELECT count(*) as PatientCount from d_patients', conn))\n",
    "display(pd.read_sql_query('SELECT count(*) as AdmissionCount from admissions', conn))\n",
    "display(pd.read_sql_query('SELECT count(*) as NoteCount from noteevents', conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admission Data\n",
    "\n",
    "- Dates and Times are randomly offset for de-identifiation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.read_sql_query('SELECT * from admissions LIMIT 5', conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis Data\n",
    "\n",
    "- Diagnoses described with ICD9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.read_sql_query('SELECT * from icd9 LIMIT 5', conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.read_sql_query('SELECT * from noteevents LIMIT 5', conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiate Patients by the Presence or Absence of a Pneumonia Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's get a frame of Patient/Admit/Pneumonia\n",
    "pneumonia_query = \"\"\"\n",
    "    SELECT \n",
    "a.subject_id\n",
    ",a.hadm_id\n",
    ",a.admit_dt\n",
    ",(CASE WHEN pneu.HADM_ID IS NOT NULL THEN 1 ELSE 0 END) as Encounter_Pneumonia_Diagnosis\n",
    "FROM admissions a\n",
    "LEFT JOIN \n",
    "(\n",
    "    SELECT\n",
    "    d.HADM_ID\n",
    "    FROM  icd9 d\n",
    "    WHERE \n",
    "        (code like '486%%')\n",
    "    GROUP BY d.HADM_ID\n",
    ") pneu\n",
    "ON a.HADM_ID = pneu.HADM_ID\n",
    "\"\"\"\n",
    "pat_admit_pneumonia_df = pd.read_sql_query(pneumonia_query, conn)\n",
    "display(pat_admit_pneumonia_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get a count of how many PNEUMONIA vs NO-PNEUMONIA admits we have\n",
    "pneumonia_admit_count_df = pat_admit_pneumonia_df.groupby('Encounter_Pneumonia_Diagnosis').size()\n",
    "display(pneumonia_admit_count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Chest X-ray reports\n",
    "\n",
    "- Note: there is no code for this so we are doing simple text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before pulling note text, let's get a distribution of how many RADIOLOGY reports\n",
    "# typically exist per admission\n",
    "visit_rad_report_count_query = \"\"\"\n",
    "SELECT\n",
    "n.hadm_id\n",
    ",count(*) as rad_note_count\n",
    "FROM d_patients p\n",
    "INNER JOIN noteevents n\n",
    "    ON n.subject_id = p.subject_id\n",
    "WHERE \n",
    "    Category = 'RADIOLOGY_REPORT' \n",
    "    AND (text like '%%CHEST (PORTABLE AP)%%' OR text like '%%CHEST (PA & LAT)%%')\n",
    "    AND n.hadm_id IS NOT NULL\n",
    "GROUP BY n.hadm_id\n",
    "ORDER BY count(*) DESC\n",
    "\"\"\"\n",
    "visit_rad_report_count_df = pd.read_sql_query(visit_rad_report_count_query, conn)\n",
    "display(visit_rad_report_count_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_rad_report_count_df['rad_note_count'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before pulling note text, let's get a distribution of how many RADIOLOGY reports\n",
    "# typically exist per admission\n",
    "visit_rad_report_count_query = \"\"\"\n",
    "SELECT\n",
    "n.hadm_id\n",
    ",count(*) as rad_note_count\n",
    "FROM d_patients p\n",
    "INNER JOIN noteevents n\n",
    "    ON n.subject_id = p.subject_id\n",
    "WHERE \n",
    "    Category = 'RADIOLOGY_REPORT' \n",
    "    AND (text like '%%CHEST (PORTABLE AP)%%' OR text like '%%CHEST (PA & LAT)%%')\n",
    "    AND n.hadm_id IS NOT NULL\n",
    "GROUP BY n.hadm_id\n",
    "ORDER BY count(*) DESC\n",
    "\"\"\"\n",
    "visit_rad_report_count_df = pd.read_sql_query(visit_rad_report_count_query, conn)\n",
    "display(visit_rad_report_count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some patients have only one radiology report but several have multiple.  This graph looks at that distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_note_count_grouping = visit_rad_report_count_df.groupby('rad_note_count').size()\n",
    "#display(rad_note_count_grouping)\n",
    "\n",
    "note_count_bins = rad_note_count_grouping.index.values\n",
    "#print(note_count_bins)\n",
    "note_frequencies = rad_note_count_grouping.values\n",
    "#print(note_frequencies)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.xlabel('Total Radiology Chest X-Ray Notes per visit')\n",
    "plt.ylabel('Total Visits')\n",
    "\n",
    "plt.bar(note_count_bins, note_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can then can pull these notes into a frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's pull a frame of all the FIRST (sorted by text which begins with date) CHEST X-RAY notes\n",
    "chest_xray_note_query = \"\"\"\n",
    "SELECT\n",
    "subject_id\n",
    ",hadm_id\n",
    ",charttime\n",
    ",LTRIM(RTRIM(text)) as text\n",
    "FROM noteevents\n",
    "WHERE category = 'RADIOLOGY_REPORT'\n",
    "    AND (text like '%%CHEST (PORTABLE AP)%%' OR text like '%%CHEST (PA & LAT)%%')\n",
    "    AND subject_id is not NULL\n",
    "    AND hadm_id is not NULL\n",
    "GROUP BY subject_id, hadm_id, charttime, text\n",
    "\"\"\"\n",
    "chest_xray_note_df = pd.read_sql_query(chest_xray_note_query, conn)\n",
    "display(chest_xray_note_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Data Together\n",
    "\n",
    "Much like a SQL \"join\" we can combine our frame which has ICD-9 codes with the frame that has notes so that we can sample from these intelligently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_note_df = pd.merge(pat_admit_pneumonia_df, chest_xray_note_df, on = ['subject_id', 'hadm_id'])\n",
    "display(pneumonia_note_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data in a Machine-Learning Friendly Manner\n",
    "\n",
    "We've created an environment that allows us to read data from a database and, if we wanted, do NLP and machine learning on the data that we've extracted. But our data isn't quite in the format that most machine learning pipelines work, which tend to expect data to be in individual files per case organized in directories by category (e.g. pneumonia/no pneumonia).\n",
    "\n",
    "So let's wrap up the notebook by writing the data in a machine-learning friendly manner.\n",
    "\n",
    "__NOTE__: Edit `OUTDIR` to match a meaningful location on your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"/Users/brian/GDrive\"\n",
    "pdir = os.path.join(OUTDIR, \"MBSI\", \"pneumonia\")\n",
    "npdir = os.path.join(OUTDIR, \"MBSI\", \"nopneumonia\")\n",
    "\n",
    "if not os.path.exists(pdir):\n",
    "    os.makedirs(pdir)\n",
    "    \n",
    "if not os.path.exists(npdir):\n",
    "    os.makedirs(npdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's list out some of the notes where Pneumonia WAS diagnosed\n",
    "pneumonia_positive_notes = pneumonia_note_df[pneumonia_note_df['Encounter_Pneumonia_Diagnosis'] == 1]['text'].head(1).values\n",
    "\n",
    "\n",
    "for index, row in pneumonia_note_df.iterrows():\n",
    "    if row['Encounter_Pneumonia_Diagnosis'] == 1:\n",
    "        odir = pdir\n",
    "    else:\n",
    "        odir = npdir\n",
    "    with open(os.path.join(odir, \"%05d.txt\"%index), \"w\") as f:\n",
    "        f.write(row['text'])\n",
    "    with open(os.path.join(odir, \"%05d.json\"%index), \"w\") as f:\n",
    "        meta = {\"subject_id\":row[\"subject_id\"], \n",
    "                \"hadm_id\":row[\"hadm_id\"],\n",
    "                \"admit_dt\":row[\"admit_dt\"].isoformat(),\n",
    "                \"charttime\":row[\"charttime\"].isoformat()}\n",
    "        json.dump(meta, f)\n",
    "    #sys.stdout.write(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "We saved all the CXR reports for each patient. If we want to use only the first report for each patient, we would have to do some NLP to identify the dates as the `charttimes` values don't seem to provide the needed granualirty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>This material is based in part on materials presented as part of the DeCART Data Science for the Health Science Summer Program at the University of Utah in 2017.<br/>\n",
    "Presenters : Dr. Wendy Chapman, Jianlin Shi and Kelly Peterson"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
